{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "Wfl7SO8UKFN6"
      ]
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Final Project: [HighwayEnv](https://github.com/Farama-Foundation/HighwayEnv/tree/master)\n",
        "\n",
        "Ressources:\n",
        "- **Highway-env** [üë®‚ÄçüíªRepo](https://github.com/Farama-Foundation/HighwayEnv/tree/master) | [üìúDocumentation](http://highway-env.farama.org/quickstart/)\n",
        "- **OpenAI Gym**\n",
        "- **Stable-Baselines3**: [üë®‚ÄçüíªRepo](https://github.com/DLR-RM/stable-baselines3) | [üìúDocumentation](https://stable-baselines.readthedocs.io/en/master/)\n",
        "\n",
        "### Your task: Solve the Highway\n",
        "![](https://raw.githubusercontent.com/eleurent/highway-env/gh-media/docs/media/highway.gif?raw=true)\n",
        "- By Group of two\n",
        "- Use *at least* two different RL Algorithms\n",
        "  - try to implement at least one 'by hand'\n",
        "\n",
        "### Evaluation\n",
        "*Based on the report (showing that you understood what you did), the performances and the code (you did something that works).*\n",
        "\n",
        "- **Produce a notebook**\n",
        "  -  The notebook must run one one go, I will not loose time trying to fix your env...\n",
        "  - Possible to send a git repo with the weight so that I ca nrun them locally.\n",
        "- **Produce a 2-5 pages report**\n",
        "  - Describe Your choices and explain the algorithms used.\n",
        "  - Benchmark and compare them depending on their hyperparameters.\n",
        "\n",
        "*Analysis could include exploration of hyperparameters, figures of training, explainations of how your algorithm works*\n",
        "\n",
        "### Roadmap\n",
        "- üìÜ **04 janv** : Send a report (5-10 pages) and a notebook / script\n",
        "\n"
      ],
      "metadata": {
        "id": "Z7APFgsL9Krs"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Utlilities\n",
        "‚ö†Ô∏è *Do not Modify anything here !*\n",
        "\n",
        "but always read everything to be sure of what is available\n",
        "\n",
        "### Imports"
      ],
      "metadata": {
        "id": "Fc1YR7k69WMT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install gymnasium>=1.0.0a2\n",
        "!pip install farama-notifications>=0.0.1\n",
        "!pip install numpy>=1.21.0\n",
        "!pip install pygame>=2.0.2\n",
        "!pip install stable-baselines3[extra]\n",
        "!pip install highway_env\n",
        "#tensorboard loading if you want to use it\n",
        "%load_ext tensorboard"
      ],
      "metadata": {
        "id": "Czc7gbW2HsKE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Utils"
      ],
      "metadata": {
        "id": "Wfl7SO8UKFN6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "### VIDEO RECORDER\n",
        "# Set up fake display; otherwise rendering will fail\n",
        "import os\n",
        "import base64\n",
        "from pathlib import Path\n",
        "from IPython import display as ipythondisplay\n",
        "from tqdm import tqdm\n",
        "\n",
        "os.system(\"Xvfb :1 -screen 0 1024x768x24 &\")\n",
        "os.environ['DISPLAY'] = ':1'\n",
        "\n",
        "from stable_baselines3.common.vec_env import VecVideoRecorder, DummyVecEnv\n",
        "\n",
        "def record_video(env_id, model, video_length=500, prefix=\"\", video_folder=\"videos/\", fps = 10):\n",
        "    \"\"\"\n",
        "    :param env_id: (str)\n",
        "    :param model: (RL model)\n",
        "    :param video_length: (int)\n",
        "    :param prefix: (str)\n",
        "    :param video_folder: (str)\n",
        "    \"\"\"\n",
        "    eval_env = DummyVecEnv([lambda: gym.make(env_id, render_mode=\"rgb_array\")])\n",
        "    eval_env.metadata[\"render_fps\"] = fps\n",
        "    # Start the video at step=0 and record 500 steps\n",
        "    eval_env = VecVideoRecorder(\n",
        "        eval_env,\n",
        "        video_folder=video_folder,\n",
        "        record_video_trigger=lambda step: step == 0,\n",
        "        video_length=video_length,\n",
        "        name_prefix=prefix,\n",
        "    )\n",
        "    obs = eval_env.reset()\n",
        "    for _ in tqdm(range(video_length)):\n",
        "        action, _ = model.predict(obs)\n",
        "        obs, _, _, _ = eval_env.step(action)\n",
        "\n",
        "    # Close the video recorder\n",
        "    eval_env.close()\n",
        "\n",
        "def show_videos(video_path=\"\", prefix=\"\"):\n",
        "    \"\"\"\n",
        "    Taken from https://github.com/eleurent/highway-env\n",
        "\n",
        "    :param video_path: (str) Path to the folder containing videos\n",
        "    :param prefix: (str) Filter the video, showing only the only starting with this prefix\n",
        "    \"\"\"\n",
        "    html = []\n",
        "    for mp4 in Path(video_path).glob(\"{}*.mp4\".format(prefix)):\n",
        "        video_b64 = base64.b64encode(mp4.read_bytes())\n",
        "        html.append(\n",
        "            \"\"\"<video alt=\"{}\" autoplay\n",
        "                    loop controls style=\"height: 200px;\">\n",
        "                    <source src=\"data:video/mp4;base64,{}\" type=\"video/mp4\" />\n",
        "                </video>\"\"\".format(\n",
        "                mp4, video_b64.decode(\"ascii\")\n",
        "            )\n",
        "        )\n",
        "    ipythondisplay.display(ipythondisplay.HTML(data=\"<br>\".join(html)))"
      ],
      "metadata": {
        "id": "BBE3MGBbKHzr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# prompt: define an evaluation function computing mean reward and elapsed episode time on a few runs of vectorized environments\n",
        "import numpy as np\n",
        "\n",
        "def evaluate(model, num_episodes=30):\n",
        "    \"\"\"\n",
        "    Evaluates a reinforcement learning agent.\n",
        "\n",
        "    Args:\n",
        "        model: The trained RL model.\n",
        "        env: The environment to evaluate the model on.\n",
        "        num_episodes: The number of episodes to run for evaluation.\n",
        "\n",
        "    Returns:\n",
        "        A tuple containing the mean reward and the mean elapsed time per episode.\n",
        "    \"\"\"\n",
        "    env_id = \"highway-fast-v0\"\n",
        "    env = make_vec_env(env_id)\n",
        "    episode_rewards = []\n",
        "    episode_times = []\n",
        "    print(f\"evaluating Model on {num_episodes} episodes ...\")\n",
        "    for _ in tqdm(range(num_episodes)):\n",
        "        obs = env.reset()\n",
        "        done = False\n",
        "        total_reward = 0\n",
        "        start_time = 0 # Assuming env provides time information. Replace with actual time tracking\n",
        "        current_time = 0\n",
        "\n",
        "        while not done:\n",
        "          action, _states = model.predict(obs, deterministic=True)\n",
        "          obs, reward, done, info = env.step(action)\n",
        "          total_reward += reward\n",
        "          current_time += 1 # Replace with actual elapsed time from env info\n",
        "\n",
        "        episode_rewards.append(total_reward)\n",
        "        episode_times.append(current_time - start_time)\n",
        "\n",
        "    mean_reward = np.mean(episode_rewards)\n",
        "    mean_time = np.mean(episode_times)\n",
        "    std_reward = np.std(episode_rewards)\n",
        "    std_time = np.std(episode_times)\n",
        "    print(f\"\\n{'-'*50}\\nResults :\\n\\t- Mean Reward: {mean_reward:.3f} ¬± {std_reward:.2f} \\n\\t- Mean elapsed Time per episode: {mean_time:.3f} ¬± {std_time:.2f}\\n{'-'*50}\")\n",
        "    return mean_reward, mean_time\n"
      ],
      "metadata": {
        "id": "PWhU7AyGjEmv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## The Highway Environment"
      ],
      "metadata": {
        "id": "g0IMoR_dHw5E"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "## IMPORTS\n",
        "import gymnasium as gym\n",
        "from stable_baselines3 import PPO, DQN\n",
        "from stable_baselines3.common.env_util import make_vec_env\n",
        "from stable_baselines3.common.vec_env import SubprocVecEnv\n",
        "import highway_env  # noqa: F401"
      ],
      "metadata": {
        "id": "N-T_1wXCV0if"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Load and explore Environment\n",
        "Lets first load an untrained model and see how it behaves in the environment."
      ],
      "metadata": {
        "id": "KFya-bWomgvJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "env_id = \"highway-fast-v0\"\n",
        "env = make_vec_env(env_id)\n",
        "#instanciate model\n",
        "model = PPO(\"MlpPolicy\", env, verbose=1)\n",
        "\n",
        "#generate video of random model\n",
        "record_video(env_id, model, video_length=50, prefix=\"random-agent\", fps = 5)\n",
        "show_videos(\"videos\", prefix=\"random-agent\")"
      ],
      "metadata": {
        "id": "yb_5iwfHeW3Z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "evaluate(model)"
      ],
      "metadata": {
        "id": "TZnWq4g0sK20"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's now explore the environments settings:\n",
        "### Action Space\n",
        "üëâ Look at the action space, what actions can the model do ?"
      ],
      "metadata": {
        "id": "MRNSVynMqHLl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "######### YOUR CODE HERE #########\n"
      ],
      "metadata": {
        "id": "n9-V7160qY7J"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Observation Space\n",
        "üëâ Look at the [documentation](http://highway-env.farama.org/observations/) for possibles observations of the agents on the Highway\n",
        "\n",
        "üëâ Look at the observation spae in our case"
      ],
      "metadata": {
        "id": "HUHmYIZhu_j-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "######### YOUR CODE HERE #########\n"
      ],
      "metadata": {
        "id": "aGYGjDlNvYIJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Training an Agent on the Environment\n",
        "üëâ **Now it is your turn**, train your agents\n",
        "Recall:\n",
        "- you must try and compare different RL Algorithms\n",
        "- part of your grade will be the evaluation of your best Agent.\n",
        "\n",
        "üî•Tips\n",
        "- Use tensorboard to monitor your trainings\n",
        "- install it locally to get faster and longer trainings (not mandatory, colab should be ok)"
      ],
      "metadata": {
        "id": "CmBZSNyxmomL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# if you want to use tensorboard, highly recommended\n",
        "%tensorboard --logdir \"highway\""
      ],
      "metadata": {
        "id": "ildCcCnxtpbB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "######### YOUR CODE HERE #########\n"
      ],
      "metadata": {
        "id": "kZUAObuMeUEV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FjNySEdF89aM"
      },
      "outputs": [],
      "source": [
        "######### SOME OTHER FANCY TRAINING HERE #########"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "### SAVE YOUR FINAL MODEL\n",
        "model_final = .... #YOUR MODEL\n",
        "model_final.save(\"highway_final\")"
      ],
      "metadata": {
        "id": "QjtLbM4x2FSP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Evalutation\n",
        "‚ö†Ô∏è *Do not Modify anything here !*\n",
        "\n",
        "Now that your Agents are trained, we evaluate them"
      ],
      "metadata": {
        "id": "Mt0SpTCBuLOE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "evaluate(model_final)"
      ],
      "metadata": {
        "id": "b9Fw8ycCuKp0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "env_id = \"highway-v0\"\n",
        "# Generate video of trained model\n",
        "record_video(env_id, model_final, video_length=70, prefix=\"trained-agent\", fps = 5)\n",
        "show_videos(\"videos\", prefix=\"trained-agent\")"
      ],
      "metadata": {
        "id": "OaZButoeyByP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# üéÅ Bonus\n",
        "If it was too easy for your, you can also try to train an agent on an even more difficult environment, for instance the `racetrack` *(see the highway env repo for other possible environments)*\n",
        "\n",
        "---\n",
        "![](https://raw.githubusercontent.com/eleurent/highway-env/gh-media/docs/media/racetrack-env.gif?raw=true)\n"
      ],
      "metadata": {
        "id": "RQL90gA0zW9b"
      }
    }
  ]
}